{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 6: Sums and products over spatial point processes                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Definition:** Let $\\Phi = \\{x_i\\} = \\{x_1,x_2,...\\} \\subset \\mathbb{R}^d$ be a point process and $f:\\mathbb{R}^d \\mapsto \\mathbb{R}$ a measurable function. A sum of $f(x)$ over $\\Phi$ can be alternatively written as:\n",
    "\n",
    "<br><center> $\\displaystyle{\\sum\\limits_{x \\in \\Phi} f(x) = \\int_{\\mathbb{R}^d} f(x)\\;\\Phi(\\mathrm{d}x) = \\int_{\\mathbb{R}^d} f(x)p(x) \\;\\mathrm{d}x},$ </center></br>\n",
    "\n",
    "where $p(x) = \\sum\\limits_{y \\in \\Phi} \\delta(x-y)$ and $\\delta(\\cdot)$ is the Dirac delta function.\n",
    "\n",
    "\n",
    "**Exemple:** The counting measure (number of points) $\\Phi(B)$ (or using different notation $N(B)$) where $B \\subset \\mathbb{R}^d$ is written as:\n",
    "\n",
    "<br><center>$\\displaystyle{\\Phi(B) = \\sum\\limits_{x \\in \\Phi} \\mathbb{1}_B(x) = \\int_{B} \\Phi(\\mathrm{d}x)}.$ </center></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.2 Mean value of the sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Such a sum is itself a random variable and therefore we can try to find some of its statistical properties. \n",
    "\n",
    "**Definition:** The mean value of the sum presented above can be written as:\n",
    "\n",
    "<br><center> $\\displaystyle{\\mathbb{E} \\left(\\sum\\limits_{x \\in \\Phi} f(x)\\right) = \\int_{\\mathcal{N}} \\sum\\limits_{x \\in \\varphi} f(x)\\;\\mathbb{P}(\\mathrm{d}\\varphi) = \\int_{\\mathcal{N}} \\int_{\\mathbb{R}^d} f(x)  \\varphi(\\mathrm{d}x) \\;\\mathbb{P}(\\mathrm{d}\\varphi)},$ </center></br>\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\varphi$ denotes a locally finite countable subset of $\\mathbb{R}^d$ and the associated counting measure: $\\varphi = \\{x_1,x_2,...\\}$,  $\\varphi(B) = \\sum\\limits_{x \\in B} \\mathbb{1}_B(x)$;\n",
    "\n",
    "\n",
    "- $\\mathcal{N}$ is the outcome space such that it is the set of all $\\varphi$ and a point process $\\Phi$ is a random choice of one of the $\\varphi$ in $\\mathcal{N}$.\n",
    "\n",
    "\n",
    "**Exemple:** Let us consider the counting measure (number of points) $\\Phi(B)$ where $B \\subset \\mathbb{R}^d$ of the last example:\n",
    "\n",
    "<br><center>$\\displaystyle{\\Phi(B) = \\sum\\limits_{x \\in \\Phi} \\mathbb{1}_B(x) = \\int_{B} \\Phi(\\mathrm{d}x)}.$ </center></br>\n",
    "\n",
    "Then, the mean value of $\\mathbb{E}\\Phi(B)$ can be written as:\n",
    "\n",
    "\n",
    "<br><center> $\\displaystyle{\\mathbb{E}\\Phi(B)= \\mathbb{E} \\left(\\sum\\limits_{x \\in \\Phi} \\mathbb{1}_B(x)\\right) = \n",
    "\\int_{\\mathcal{N}}  \\varphi(B) \\;\\mathbb{P}(\\mathrm{d}\\varphi)} = \n",
    "\\int_{\\mathcal{N}} \\sum\\limits_{x \\in \\varphi} \\mathbb{1}_B(x) \\; \\mathbb{P}(\\mathrm{d}\\varphi) = \n",
    "\\int_{\\mathcal{N}} \\int_{\\mathbb{R}^d} \\mathbb{1}_B(x) \\;\\varphi(\\mathrm{d}x) \\mathbb{P}(\\mathrm{d}\\varphi) =\n",
    "\\int_{\\mathcal{N}} \\int_{B} \\varphi(\\mathrm{d}x) \\mathbb{P}(\\mathrm{d}\\varphi)$.  </center></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.3 Campbell's theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Definition:** Let $\\Phi$ be a point process in  $S = \\mathbb{R}^d$. Then, $\\Lambda(B) = \\mathbb{E}N(B),\\; B \\subset S$, defines the  **intensity measure** $\\Lambda$ on S, provided that $\\Lambda(B) < \\infty$ for all compact $B$.\n",
    "\n",
    "**Definition:** If the intensity measure $\\Lambda$ of a point process $\\Phi$ in  $\\mathbb{R}^d$ satisfies $\\displaystyle \\Lambda(B) = \\int_{B} \\lambda(u) \\; \\mathrm{d}u$ for some function $\\lambda$, then we call $\\lambda$ the **intensity function** of $\\Phi$.\n",
    "\n",
    "\n",
    "**Theorem:** Let $\\Phi$ be a point process in  $\\mathbb{R}^d$ and $f:\\mathbb{R}^d \\mapsto \\mathbb{R}$ be a measurable function. Then the random sum:\n",
    "\n",
    "<br><center> $S = \\displaystyle{\\sum\\limits_{x \\in \\Phi} f(x)}$ </center></br>\n",
    "\n",
    "is a random variable with mean\n",
    "\n",
    "<br><center> $\\mathbb{E}S = \\displaystyle{\\int_{\\mathbb{R}^d} f(x) \\; \\Lambda(\\mathrm{d}x)}.$ </center></br>\n",
    "\n",
    "\n",
    "If $\\Phi$ has an intensity function $\\lambda(x)$, then\n",
    "\n",
    "<br><center> $\\mathbb{E}S = \\displaystyle{\\int_{\\mathbb{R}^d} f(x) \\lambda(x) \\; \\mathrm{d}x}.$ </center></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Outline of proof* \n",
    "\n",
    "- Assume that $f$ is a step function such that: $\\displaystyle f = \\sum\\limits_{i=1}^m c_i \\mathbb{1}_{B_i}$ for $B_i \\subset \\mathbb{R}^d$ and $c_i \\in \\mathbb{R}.$\n",
    "\n",
    "\n",
    "- $S = \\displaystyle{\\sum\\limits_{x \\in \\Phi} f(x)} = \\displaystyle{\\sum\\limits_{x \\in \\Phi} \\sum\\limits_{i=1}^m c_i \\mathbb{1}_{B_i}(x)} = \\sum\\limits_{i=1}^m c_i \\Phi(B_i).$\n",
    "\n",
    "\n",
    "- $\\displaystyle \\mathbb{E}S = \\mathbb{E}\\left( \\sum\\limits_{i=1}^m c_i \\Phi(B_i) \\right) = \\sum\\limits_{i=1}^m c_i \\mathbb{E}\\Phi(B_i) = \\int_{\\mathbb{R}^d} f(x) \\; \\Lambda(\\mathrm{d}x).$\n",
    "\n",
    "\n",
    "- The result for general $f$ follows by monotone approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Compute $\\mathbb{E}S$ when $\\Phi$ is a stationary point process in $\\mathbb{R}^d$.\n",
    "\n",
    "*Hint:* Remember the intensity function for stationary processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review:** The generating function $G_X$ of a non-negative integer-valued random variable $X$ is given by $\\displaystyle G_X(t) \\triangleq \\mathbb{E}\\left(t^X \\right) = \\sum\\limits_{n=0}^\\infty t^n \\mathbb{P}(X=n)$ for $t \\in [0,1].$ In this case: $\\mathbb{E}\\left(X \\right) = G'_X(1)$ and $\\mathrm{var}\\left(X \\right) = G''_X(1)+G'_X(1)(1-G'_X(1))$.\n",
    "\n",
    "Now we generalize this idea so as to define the probability generating functional of a point process.\n",
    "\n",
    "**Definition:** Let $\\mathcal{V}$ be the family of all measurable functions $v: \\mathbb{R}^d \\mapsto [0,1]$ such that $1-v$ has a bounded support (i.e. $v \\in \\mathcal{V}$ means that $1-v(x)$ vanishes outside a bounded set). For $v \\in \\mathcal{V}$, the probability generating functional (pgfl) of the point process $\\Phi$ is defined as\n",
    "\n",
    "<br><center> $\\displaystyle G[v] \\triangleq \\mathbb{E}\\left( \\prod\\limits_{x\\in \\Phi} v(x) \\right) = \\int_\\mathcal{N} \\prod\\limits_{x\\in \\Phi} v(x) \\; \\mathbb{P}(\\mathrm{d}\\varphi).$</center></br>\n",
    "\n",
    "Alternatively,\n",
    "\n",
    "<br><center> $\\displaystyle G[v] \\triangleq \\mathbb{E}\\left[ \\exp\\left( \\sum\\limits_{x \\in \\Phi} \\log v(x) \\right) \\right] = \n",
    "\\mathbb{E}\\left[ \\exp\\left( \\int_{\\mathbb{R}^d} \\log v(x) \\; \\Phi(\\mathrm{d}x)\\right) \\right].$ </center></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relation to the moment-generating functional and Laplace transform** \n",
    "\n",
    "- Define the moment-generating function of a random variable $X$ as $\\displaystyle M_X(t) \\triangleq \\mathbb{E}\\left( e^{tX} \\right), \\; t \\in \\mathbb{R}$.\n",
    "\n",
    "\n",
    "- Laplace transform of a random variable $X$ is $\\displaystyle \\mathcal{L}_X(s) = \\mathbb{E}\\left( e^{-sX} \\right), \\; s \\in \\mathbb{C}$.\n",
    "\n",
    "\n",
    "- The sum $\\displaystyle S[\\log v] = \\sum\\limits_{x \\in \\Phi} \\log v(x)$, we can then write the pgfl as $G[v] = \\mathbb{E}\\left( e^{S[\\log v] }\\right)$.\n",
    "\n",
    "\n",
    "- Replacing $\\displaystyle X = S[\\log v]$, we have $\\displaystyle M_{S[\\log v]}(t) = \\mathbb{E}\\left( e^{tS[\\log v]} \\right)$.\n",
    "\n",
    "\n",
    "- Then: $G[v] = \\mathcal{L}_{S[\\log v]}(-1)$ (note that $v \\in [0,1]$ then these quantities are well defined).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Laplace functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Definition:** Let $\\Psi$ be a non-negative random measure on $\\mathbb{R}^d$, and let $\\mathcal{U}$ be the set of all bounded non-negative measurable functions $u$ of bounded support. For $u \\in \\mathcal{U}$, the Laplace functional is defined as: \n",
    "\n",
    "<br><center> $\\displaystyle L_\\Psi[u] \\triangleq = \\mathbb{E}\\left[ \\exp\\left( - \\int_{\\mathbb{R}^d} \\log u(x) \\; \\Psi(\\mathrm{d}x)\\right) \\right].$  </center></br>\n",
    "\n",
    "If the Laplace functional is applied to a point process (random counting measure $\\Phi$), then we can drop the subscript is if there is no danger of confusion.\n",
    "\n",
    "**Relation to probability generating functional**\n",
    "\n",
    "For a point process $\\Phi$:\n",
    "\n",
    "- $L[u] \\equiv G[e^{-u}]$ for $u \\in \\mathcal{U}$, or\n",
    "\n",
    "\n",
    "- $G[v] \\equiv L[-\\log v]$ for $v \\in \\mathcal{V}$.\n",
    "\n",
    "If a function $u \\in \\mathcal{U}$, then $e^{-u} \\in \\mathcal{V}$. Conversely, $v \\in \\mathcal{V}$, then $-\\log v \\in \\mathcal{U}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Moment-generating function of sums over Poisson processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Theorem (Campbell):** Let $\\Phi$ be a uniform Poisson point process of intensity $\\lambda$ on $\\mathbb{R}^d$ and $f: \\mathbb{R}^d \\mapsto \\mathbb{R}$ a measurable function. Then the sum:\n",
    "\n",
    "<br><center> $S = \\displaystyle{\\sum\\limits_{x \\in \\Phi} f(x)}$ </center></br>\n",
    "\n",
    "is absolutely convergent almost surely if and only if \n",
    "\n",
    "<br><center> $\\displaystyle{\\int_{\\mathbb{R}^d} \\min(f(x),1) \\; \\mathrm{d}x} < \\infty.$ </center></br>\n",
    "\n",
    "\n",
    "If it is, the moment-generating function is given by\n",
    "\n",
    "<br><center> $\\displaystyle \\mathbb{E}\\left(e^{tS}\\right) = \\exp\\left( \\lambda \\int_{\\mathbb{R}^d} \\left(e^{tf(x)}-1\\right) \\; \\mathrm{d}x \\right).$ </center></br>\n",
    "\n",
    "\n",
    "**Definition:** If we express the moment-generating function in terms of the function $f$ and setting $t=1$, we define the *characteristic functional* of the Poisson point process as:\n",
    "\n",
    "<br><center> $\\displaystyle \\mathbb{E}\\left(e^{S[f]}\\right) = \\mathbb{E}\\left( \\exp\\left(\\int_{\\mathbb{R}^d}f(x) \\; \\Phi(\\mathrm{d}x) \\right)  \\right) = \\exp\\left( \\lambda \\int_{\\mathbb{R}^d} \\left(e^{f(x)}-1\\right) \\; \\mathrm{d}x \\right).$ </center></br>\n",
    "\n",
    "\n",
    "\n",
    "**Exercise:** Let $S = \\displaystyle{\\sum\\limits_{x \\in \\Phi} f(x)}$ for a homogeneous Poisson point process $\\Phi \\in \\mathbb{R}^d$ with intensity $\\lambda$. Find (a) $\\mathbb{E}S$ and (b) $\\mathrm{var}(S) = \\mathbb{E}S^2 - (\\mathbb{E}S)^2$.\n",
    "\n",
    "*Hint:* $\\mathbb{E}X^n = \\left.\\dfrac{\\partial^n}{\\partial t^n}M_X(t)\\right|_{t=0}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Probability generating and Laplace functionals for Poisson point processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem:** Let $v \\in \\mathcal{V}$ be measurable, and $\\Phi$ be a Poisson process with intensity $\\Lambda$. Then:\n",
    "\n",
    "<br><center> \n",
    "$\\displaystyle G[v] \\triangleq \\mathbb{E}\\left( \\prod\\limits_{x\\in \\phi} v(x) \\right) = \\exp\\left( - \\int_{\\mathbb{R}^d} (1-v(x)) \\; \\Lambda(\\mathrm{d}x)  \\right).$\n",
    "</center></br>\n",
    "\n",
    "The Laplace functional is then:\n",
    "\n",
    "<br><center> \n",
    "$\\displaystyle L[u] \\equiv G[e^{-u}] = \\exp\\left( - \\int_{\\mathbb{R}^d} \\left(1-e^{-u(x)} \\right) \\; \\Lambda(\\mathrm{d}x)  \\right).$\n",
    "</center></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Let $\\Phi$ be a uniform Poisson point process in $\\mathbb{R}^d$ of intensity $\\lambda$. Let $v(x) = 1 - \\mathbb{1}_B(x)$. Then the event $\\Phi(B) = 0$ can be expressed as $\\displaystyle \\prod\\limits_{x\\in \\phi} v(x)=1$. It occurs with probability \n",
    "\n",
    "<br><center> \n",
    "$\\mathbb{P}(\\Phi(B) = 0) =  \\displaystyle \\mathbb{E}\\left( \\prod\\limits_{x\\in \\phi} v(x) \\right) = G[v] = e^{-\\lambda |B|}.$\n",
    "</center></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[1] A. Baddeley, *Spatial Point Processes and their Applications*, pages 26-30.\n",
    "\n",
    "[2] M. Haenngi, *Stochastic Geometry for Wireless Networks*, pages 24-34 and 77-88."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (SageMath)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "lecture6.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
